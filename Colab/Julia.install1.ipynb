{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Julia on Colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Julia",
      "language": "julia",
      "name": "julia"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.5.2"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMSuTc3pDlHv",
        "outputId": "e3b7a2e2-41b7-4d64-ef72-133a64572fd5"
      },
      "source": [
        "%%shell\n",
        "set -e\n",
        "\n",
        "#---------------------------------------------------#\n",
        "JULIA_VERSION=\"1.5.2\" # any version ≥ 0.7.0\n",
        "JULIA_PACKAGES=\"IJulia BenchmarkTools PyCall PyPlot Knet HDF5\"\n",
        "JULIA_PACKAGES_IF_GPU=\"CUDA\"\n",
        "JULIA_NUM_THREADS=4\n",
        "#---------------------------------------------------#\n",
        "\n",
        "if [ -n \"$COLAB_GPU\" ] && [ -z `which julia` ]; then\n",
        "  # Install Julia\n",
        "  JULIA_VER=`cut -d '.' -f -2 <<< \"$JULIA_VERSION\"`\n",
        "  echo \"Installing Julia $JULIA_VERSION on the current Colab Runtime...\"\n",
        "  BASE_URL=\"https://julialang-s3.julialang.org/bin/linux/x64\"\n",
        "  URL=\"$BASE_URL/$JULIA_VER/julia-$JULIA_VERSION-linux-x86_64.tar.gz\"\n",
        "  wget -nv $URL -O /tmp/julia.tar.gz # -nv means \"not verbose\"\n",
        "  tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1\n",
        "  rm /tmp/julia.tar.gz\n",
        "\n",
        "  # Install Packages\n",
        "  if [ \"$COLAB_GPU\" = \"1\" ]; then\n",
        "      JULIA_PACKAGES=\"$JULIA_PACKAGES $JULIA_PACKAGES_IF_GPU\"\n",
        "  fi\n",
        "  for PKG in `echo $JULIA_PACKAGES`; do\n",
        "    echo \"Installing Julia package $PKG...\"\n",
        "    julia -e 'using Pkg; pkg\"add '$PKG'; precompile;\"'\n",
        "  done\n",
        "\n",
        "  # Install kernel and rename it to \"julia\"\n",
        "  echo \"Installing IJulia kernel...\"\n",
        "  julia -e 'using IJulia; IJulia.installkernel(\"julia\", env=Dict(\n",
        "      \"JULIA_NUM_THREADS\"=>\"'\"$JULIA_NUM_THREADS\"'\"))'\n",
        "  KERNEL_DIR=`julia -e \"using IJulia; print(IJulia.kerneldir())\"`\n",
        "  KERNEL_NAME=`ls -d \"$KERNEL_DIR\"/julia*`\n",
        "  mv -f $KERNEL_NAME \"$KERNEL_DIR\"/julia\n",
        "\n",
        "  echo ''\n",
        "  echo \"Successfully installed `julia -v`!\"\n",
        "  echo \"Please reload this page (press Ctrl+R, ⌘+R, or the F5 key) then\"\n",
        "  echo \"jump to the 'Checking the Installation' section.\"\n",
        "fi\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing Julia 1.5.2 on the current Colab Runtime...\n",
            "2020-11-26 20:52:51 URL:https://storage.googleapis.com/julialang2/bin/linux/x64/1.5/julia-1.5.2-linux-x86_64.tar.gz [105324048/105324048] -> \"/tmp/julia.tar.gz\" [1]\n",
            "Installing Julia package IJulia...\n",
            "\u001b[32m\u001b[1m Installing\u001b[22m\u001b[39m known registries into `~/.julia`\n",
            "######################################################################## 100.0%\n",
            "\u001b[32m\u001b[1m      Added\u001b[22m\u001b[39m registry `General` to `~/.julia/registries/General`\n",
            "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m VersionParsing ── v1.2.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Artifacts ─────── v1.3.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Parsers ───────── v1.0.12\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m ZMQ ───────────── v1.2.1\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m MbedTLS ───────── v1.0.3\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m IJulia ────────── v1.23.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m MbedTLS_jll ───── v2.16.8+1\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m ZeroMQ_jll ────── v4.3.2+5\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Conda ─────────── v1.5.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m JLLWrappers ───── v1.1.3\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m SoftGlobalScope ─ v1.1.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m JSON ──────────── v0.21.1\n",
            "\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: ZeroMQ\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: MbedTLS\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Project.toml`\n",
            " \u001b[90m [7073ff75] \u001b[39m\u001b[92m+ IJulia v1.23.0\u001b[39m\n",
            "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Manifest.toml`\n",
            " \u001b[90m [56f22d72] \u001b[39m\u001b[92m+ Artifacts v1.3.0\u001b[39m\n",
            " \u001b[90m [8f4d0f93] \u001b[39m\u001b[92m+ Conda v1.5.0\u001b[39m\n",
            " \u001b[90m [7073ff75] \u001b[39m\u001b[92m+ IJulia v1.23.0\u001b[39m\n",
            " \u001b[90m [692b3bcd] \u001b[39m\u001b[92m+ JLLWrappers v1.1.3\u001b[39m\n",
            " \u001b[90m [682c06a0] \u001b[39m\u001b[92m+ JSON v0.21.1\u001b[39m\n",
            " \u001b[90m [739be429] \u001b[39m\u001b[92m+ MbedTLS v1.0.3\u001b[39m\n",
            " \u001b[90m [c8ffd9c3] \u001b[39m\u001b[92m+ MbedTLS_jll v2.16.8+1\u001b[39m\n",
            " \u001b[90m [69de0a69] \u001b[39m\u001b[92m+ Parsers v1.0.12\u001b[39m\n",
            " \u001b[90m [b85f4697] \u001b[39m\u001b[92m+ SoftGlobalScope v1.1.0\u001b[39m\n",
            " \u001b[90m [81def892] \u001b[39m\u001b[92m+ VersionParsing v1.2.0\u001b[39m\n",
            " \u001b[90m [c2297ded] \u001b[39m\u001b[92m+ ZMQ v1.2.1\u001b[39m\n",
            " \u001b[90m [8f1865be] \u001b[39m\u001b[92m+ ZeroMQ_jll v4.3.2+5\u001b[39m\n",
            " \u001b[90m [2a0f44e3] \u001b[39m\u001b[92m+ Base64\u001b[39m\n",
            " \u001b[90m [ade2ca70] \u001b[39m\u001b[92m+ Dates\u001b[39m\n",
            " \u001b[90m [8ba89e20] \u001b[39m\u001b[92m+ Distributed\u001b[39m\n",
            " \u001b[90m [7b1f6079] \u001b[39m\u001b[92m+ FileWatching\u001b[39m\n",
            " \u001b[90m [b77e0a4c] \u001b[39m\u001b[92m+ InteractiveUtils\u001b[39m\n",
            " \u001b[90m [76f85450] \u001b[39m\u001b[92m+ LibGit2\u001b[39m\n",
            " \u001b[90m [8f399da3] \u001b[39m\u001b[92m+ Libdl\u001b[39m\n",
            " \u001b[90m [56ddb016] \u001b[39m\u001b[92m+ Logging\u001b[39m\n",
            " \u001b[90m [d6f4376e] \u001b[39m\u001b[92m+ Markdown\u001b[39m\n",
            " \u001b[90m [a63ad114] \u001b[39m\u001b[92m+ Mmap\u001b[39m\n",
            " \u001b[90m [44cfe95a] \u001b[39m\u001b[92m+ Pkg\u001b[39m\n",
            " \u001b[90m [de0858da] \u001b[39m\u001b[92m+ Printf\u001b[39m\n",
            " \u001b[90m [3fa0cd96] \u001b[39m\u001b[92m+ REPL\u001b[39m\n",
            " \u001b[90m [9a3f8284] \u001b[39m\u001b[92m+ Random\u001b[39m\n",
            " \u001b[90m [ea8e919c] \u001b[39m\u001b[92m+ SHA\u001b[39m\n",
            " \u001b[90m [9e88b42a] \u001b[39m\u001b[92m+ Serialization\u001b[39m\n",
            " \u001b[90m [6462fe0b] \u001b[39m\u001b[92m+ Sockets\u001b[39m\n",
            " \u001b[90m [8dfed614] \u001b[39m\u001b[92m+ Test\u001b[39m\n",
            " \u001b[90m [cf7118a7] \u001b[39m\u001b[92m+ UUIDs\u001b[39m\n",
            " \u001b[90m [4ec0a83e] \u001b[39m\u001b[92m+ Unicode\u001b[39m\n",
            "\u001b[32m\u001b[1m   Building\u001b[22m\u001b[39m Conda ─→ `~/.julia/packages/Conda/x5ml4/deps/build.log`\n",
            "\u001b[32m\u001b[1m   Building\u001b[22m\u001b[39m IJulia → `~/.julia/packages/IJulia/ljYVo/deps/build.log`\n",
            "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "Installing Julia package BenchmarkTools...\n",
            "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
            "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m BenchmarkTools ─ v0.5.0\n",
            "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Project.toml`\n",
            " \u001b[90m [6e4b80f9] \u001b[39m\u001b[92m+ BenchmarkTools v0.5.0\u001b[39m\n",
            "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Manifest.toml`\n",
            " \u001b[90m [6e4b80f9] \u001b[39m\u001b[92m+ BenchmarkTools v0.5.0\u001b[39m\n",
            " \u001b[90m [37e2e46d] \u001b[39m\u001b[92m+ LinearAlgebra\u001b[39m\n",
            " \u001b[90m [2f01184e] \u001b[39m\u001b[92m+ SparseArrays\u001b[39m\n",
            " \u001b[90m [10745b16] \u001b[39m\u001b[92m+ Statistics\u001b[39m\n",
            "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "Installing Julia package PyCall...\n",
            "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
            "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m MacroTools ─ v0.5.6\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m PyCall ───── v1.92.1\n",
            "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Project.toml`\n",
            " \u001b[90m [438e738f] \u001b[39m\u001b[92m+ PyCall v1.92.1\u001b[39m\n",
            "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Manifest.toml`\n",
            " \u001b[90m [1914dd2f] \u001b[39m\u001b[92m+ MacroTools v0.5.6\u001b[39m\n",
            " \u001b[90m [438e738f] \u001b[39m\u001b[92m+ PyCall v1.92.1\u001b[39m\n",
            "\u001b[32m\u001b[1m   Building\u001b[22m\u001b[39m PyCall → `~/.julia/packages/PyCall/BcTLp/deps/build.log`\n",
            "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "Installing Julia package PyPlot...\n",
            "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
            "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m LaTeXStrings ────── v1.2.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m PyPlot ──────────── v2.9.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m FixedPointNumbers ─ v0.8.4\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Reexport ────────── v0.2.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m ColorTypes ──────── v0.10.9\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Colors ──────────── v0.12.4\n",
            "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Project.toml`\n",
            " \u001b[90m [d330b81b] \u001b[39m\u001b[92m+ PyPlot v2.9.0\u001b[39m\n",
            "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Manifest.toml`\n",
            " \u001b[90m [3da002f7] \u001b[39m\u001b[92m+ ColorTypes v0.10.9\u001b[39m\n",
            " \u001b[90m [5ae59095] \u001b[39m\u001b[92m+ Colors v0.12.4\u001b[39m\n",
            " \u001b[90m [53c48c17] \u001b[39m\u001b[92m+ FixedPointNumbers v0.8.4\u001b[39m\n",
            " \u001b[90m [b964fa9f] \u001b[39m\u001b[92m+ LaTeXStrings v1.2.0\u001b[39m\n",
            " \u001b[90m [d330b81b] \u001b[39m\u001b[92m+ PyPlot v2.9.0\u001b[39m\n",
            " \u001b[90m [189a3867] \u001b[39m\u001b[92m+ Reexport v0.2.0\u001b[39m\n",
            "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "Installing Julia package Knet...\n",
            "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
            "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Adapt ──────────────────────── v2.3.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m CEnum ──────────────────────── v0.4.1\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m AbstractFFTs ───────────────── v0.5.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Requires ───────────────────── v1.1.1\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Compat ─────────────────────── v3.23.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m DataStructures ─────────────── v0.18.8\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m AutoGrad ───────────────────── v1.2.3\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Zlib_jll ───────────────────── v1.2.11+18\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m BFloat16s ──────────────────── v0.1.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m CodecZlib ──────────────────── v0.7.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m GPUCompiler ────────────────── v0.8.3\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Scratch ────────────────────── v1.0.3\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m ExprTools ──────────────────── v0.1.3\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m OrderedCollections ─────────── v1.3.2\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Knet ───────────────────────── v1.4.3\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m CompilerSupportLibraries_jll ─ v0.3.4+0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m FileIO ─────────────────────── v1.4.4\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m TranscodingStreams ─────────── v0.9.5\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m NNlib ──────────────────────── v0.7.7\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m GPUArrays ──────────────────── v6.1.2\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m JLD2 ───────────────────────── v0.2.4\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m LLVM ───────────────────────── v3.4.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m SpecialFunctions ───────────── v0.10.3\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m OpenSpecFun_jll ────────────── v0.5.3+4\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m CUDA ───────────────────────── v2.3.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m TimerOutputs ───────────────── v0.5.7\n",
            "\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: libknet8\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: Zlib\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: CompilerSupportLibraries\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: OpenSpecFun\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Project.toml`\n",
            " \u001b[90m [1902f260] \u001b[39m\u001b[92m+ Knet v1.4.3\u001b[39m\n",
            "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Manifest.toml`\n",
            " \u001b[90m [621f4979] \u001b[39m\u001b[92m+ AbstractFFTs v0.5.0\u001b[39m\n",
            " \u001b[90m [79e6a3ab] \u001b[39m\u001b[92m+ Adapt v2.3.0\u001b[39m\n",
            " \u001b[90m [6710c13c] \u001b[39m\u001b[92m+ AutoGrad v1.2.3\u001b[39m\n",
            " \u001b[90m [ab4f0b2a] \u001b[39m\u001b[92m+ BFloat16s v0.1.0\u001b[39m\n",
            " \u001b[90m [fa961155] \u001b[39m\u001b[92m+ CEnum v0.4.1\u001b[39m\n",
            " \u001b[90m [052768ef] \u001b[39m\u001b[92m+ CUDA v2.3.0\u001b[39m\n",
            " \u001b[90m [944b1d66] \u001b[39m\u001b[92m+ CodecZlib v0.7.0\u001b[39m\n",
            " \u001b[90m [34da2185] \u001b[39m\u001b[92m+ Compat v3.23.0\u001b[39m\n",
            " \u001b[90m [e66e0078] \u001b[39m\u001b[92m+ CompilerSupportLibraries_jll v0.3.4+0\u001b[39m\n",
            " \u001b[90m [864edb3b] \u001b[39m\u001b[92m+ DataStructures v0.18.8\u001b[39m\n",
            " \u001b[90m [e2ba6199] \u001b[39m\u001b[92m+ ExprTools v0.1.3\u001b[39m\n",
            " \u001b[90m [5789e2e9] \u001b[39m\u001b[92m+ FileIO v1.4.4\u001b[39m\n",
            " \u001b[90m [0c68f7d7] \u001b[39m\u001b[92m+ GPUArrays v6.1.2\u001b[39m\n",
            " \u001b[90m [61eb1bfa] \u001b[39m\u001b[92m+ GPUCompiler v0.8.3\u001b[39m\n",
            " \u001b[90m [033835bb] \u001b[39m\u001b[92m+ JLD2 v0.2.4\u001b[39m\n",
            " \u001b[90m [1902f260] \u001b[39m\u001b[92m+ Knet v1.4.3\u001b[39m\n",
            " \u001b[90m [929cbde3] \u001b[39m\u001b[92m+ LLVM v3.4.0\u001b[39m\n",
            " \u001b[90m [872c559c] \u001b[39m\u001b[92m+ NNlib v0.7.7\u001b[39m\n",
            " \u001b[90m [efe28fd5] \u001b[39m\u001b[92m+ OpenSpecFun_jll v0.5.3+4\u001b[39m\n",
            " \u001b[90m [bac558e1] \u001b[39m\u001b[92m+ OrderedCollections v1.3.2\u001b[39m\n",
            " \u001b[90m [ae029012] \u001b[39m\u001b[92m+ Requires v1.1.1\u001b[39m\n",
            " \u001b[90m [6c6a2e73] \u001b[39m\u001b[92m+ Scratch v1.0.3\u001b[39m\n",
            " \u001b[90m [276daf66] \u001b[39m\u001b[92m+ SpecialFunctions v0.10.3\u001b[39m\n",
            " \u001b[90m [a759f4b9] \u001b[39m\u001b[92m+ TimerOutputs v0.5.7\u001b[39m\n",
            " \u001b[90m [3bb67fe8] \u001b[39m\u001b[92m+ TranscodingStreams v0.9.5\u001b[39m\n",
            " \u001b[90m [83775a58] \u001b[39m\u001b[92m+ Zlib_jll v1.2.11+18\u001b[39m\n",
            " \u001b[90m [8bb1440f] \u001b[39m\u001b[92m+ DelimitedFiles\u001b[39m\n",
            " \u001b[90m [1a1011a3] \u001b[39m\u001b[92m+ SharedArrays\u001b[39m\n",
            "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "Installing Julia package HDF5...\n",
            "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
            "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Blosc_jll ─── v1.14.3+1\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m LibCURL_jll ─ v7.70.0+2\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m OpenSSL_jll ─ v1.1.1+6\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Zstd_jll ──── v1.4.5+2\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m nghttp2_jll ─ v1.40.0+2\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m LibSSH2_jll ─ v1.9.0+3\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Blosc ─────── v0.7.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m HDF5 ──────── v0.14.1\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Lz4_jll ───── v1.9.2+2\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m HDF5_jll ──── v1.12.0+1\n",
            "\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: Blosc\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: LibCURL\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: OpenSSL\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: LibSSH2\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: Zstd\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: nghttp2\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: Lz4\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: HDF5\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Project.toml`\n",
            " \u001b[90m [f67ccb44] \u001b[39m\u001b[92m+ HDF5 v0.14.1\u001b[39m\n",
            "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Manifest.toml`\n",
            " \u001b[90m [a74b3585] \u001b[39m\u001b[92m+ Blosc v0.7.0\u001b[39m\n",
            " \u001b[90m [0b7ba130] \u001b[39m\u001b[92m+ Blosc_jll v1.14.3+1\u001b[39m\n",
            " \u001b[90m [f67ccb44] \u001b[39m\u001b[92m+ HDF5 v0.14.1\u001b[39m\n",
            " \u001b[90m [0234f1f7] \u001b[39m\u001b[92m+ HDF5_jll v1.12.0+1\u001b[39m\n",
            " \u001b[90m [deac9b47] \u001b[39m\u001b[92m+ LibCURL_jll v7.70.0+2\u001b[39m\n",
            " \u001b[90m [29816b5a] \u001b[39m\u001b[92m+ LibSSH2_jll v1.9.0+3\u001b[39m\n",
            " \u001b[90m [5ced341a] \u001b[39m\u001b[92m+ Lz4_jll v1.9.2+2\u001b[39m\n",
            " \u001b[90m [458c3c95] \u001b[39m\u001b[92m+ OpenSSL_jll v1.1.1+6\u001b[39m\n",
            " \u001b[90m [3161d3a3] \u001b[39m\u001b[92m+ Zstd_jll v1.4.5+2\u001b[39m\n",
            " \u001b[90m [8e850ede] \u001b[39m\u001b[92m+ nghttp2_jll v1.40.0+2\u001b[39m\n",
            "\u001b[32m\u001b[1m   Building\u001b[22m\u001b[39m HDF5 → `~/.julia/packages/HDF5/LW5kO/deps/build.log`\n",
            "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "Installing Julia package CUDA...\n",
            "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
            "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Project.toml`\n",
            " \u001b[90m [052768ef] \u001b[39m\u001b[92m+ CUDA v2.3.0\u001b[39m\n",
            "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.5/Manifest.toml`\n",
            "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "Installing IJulia kernel...\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mInstalling julia kernelspec in /root/.local/share/jupyter/kernels/julia-1.5\n",
            "\n",
            "Successfully installed julia version 1.5.2!\n",
            "Please reload this page (press Ctrl+R, ⌘+R, or the F5 key) then\n",
            "jump to the 'Checking the Installation' section.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Rj1z5bRVKXk"
      },
      "source": [
        "# How to run?\n",
        "\n",
        "First know that this is a one-script notebook to run the entire project. \n",
        "\n",
        "\n",
        "1.   Run upper cell. (It install julia 1.5.2)\n",
        "2.   Restart the notebook. (This allows you to use julia language)\n",
        "3.   \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDjxPoocUt7y",
        "outputId": "48e5aee0-a9b7-4dee-d7c5-75a22c7e2244"
      },
      "source": [
        "versioninfo()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Julia Version 1.5.2\n",
            "Commit 539f3ce943 (2020-09-23 23:17 UTC)\n",
            "Platform Info:\n",
            "  OS: Linux (x86_64-pc-linux-gnu)\n",
            "  CPU: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "  WORD_SIZE: 64\n",
            "  LIBM: libopenlibm\n",
            "  LLVM: libLLVM-9.0.1 (ORCJIT, broadwell)\n",
            "Environment:\n",
            "  JULIA_NUM_THREADS = 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkaaAoQ6vYnH"
      },
      "source": [
        "# DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w-SGh8mvaxg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_iwHl04vcxg"
      },
      "source": [
        "# Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "629S-2a3vgAg"
      },
      "source": [
        "\n",
        "\n",
        "function aproxLogFact(n)\n",
        "    \"\"\"\n",
        "    Approximation for log n!\n",
        "    \"\"\"\n",
        "    Float32(n * log(n) - n  + log(n * (1 + 4n * (1 + 2n)))/6 + log(π)/2)\n",
        "end\n",
        "\n",
        "\n",
        "function multinomial_nll(ypred, ytrue)\n",
        "    pV = ypred ./ sum(ypred, dims=1)\n",
        "    logPV = log.(pV)\n",
        "    pS = sum(logPV .* ytrue, dims=1)\n",
        "    n = sum(ytrue, dims=1)\n",
        "    nS = (aproxLogFact.(n) .- sum(aproxLogFact.(ytrue), dims=1))\n",
        "    logP = pS .+ nS\n",
        "    loss = sum(logP) / prod(size(logP))\n",
        "end\n",
        "\n",
        "function mse(ypred, ytrue)\n",
        "    λ = Float32(0.5) * sum(ypred) / size(ypred, 1)\n",
        "    C = λ * abs2.(log.(1 .+ sum(ypred)) .- log.(1 .+ ytrue)) ./ size(ypred, 1)\n",
        "    sum(C) / prod(size(C))\n",
        "end\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vljgfJ1kvj_-"
      },
      "source": [
        "# Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8E7ygsZvmBz"
      },
      "source": [
        "\n",
        "\n",
        "mutable struct Conv\n",
        "    w\n",
        "    b\n",
        "    f\n",
        "    pDrop\n",
        "    padding\n",
        "    dilation\n",
        "    nParameters\n",
        "end\n",
        "\n",
        "\n",
        "\n",
        "(c::Conv)(x) =\n",
        "    c.f.(\n",
        "        conv4(\n",
        "            c.w,\n",
        "            dropout(x, c.pDrop),\n",
        "            padding=c.padding,\n",
        "            dilation=c.dilation\n",
        "        ) .+ c.b\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "Conv(w1::Int, w2::Int, cx::Int, cy::Int;\n",
        "    f=\n",
        "        relu,\n",
        "    pDrop=\n",
        "        0,\n",
        "    padding=\n",
        "        0,\n",
        "    dilation=\n",
        "        1,\n",
        "    xType=\n",
        "        Array{Float32},\n",
        "    scale=\n",
        "        0.01\n",
        "    ) = Conv(\n",
        "            Param(xType(rand(w1,w2,cx,cy)) .* eltype(xType)(scale), Adam()),\n",
        "            Param(xType(zeros(1,1,cy,1)), Adam()),\n",
        "            f,\n",
        "            pDrop,\n",
        "            padding,\n",
        "            dilation,\n",
        "            (w1*w2*cx +1)*cy\n",
        "        )\n",
        "\n",
        "################################################################################\n",
        "struct Pool\n",
        "    wSize\n",
        "    nParameters\n",
        "end\n",
        "\n",
        "(p::Pool)(x) = pool(x; window=p.wSize)\n",
        "Pool(x) = Pool(x, 0)\n",
        "################################################################################\n",
        "mutable struct BatchNorm\n",
        "    moments\n",
        "    params\n",
        "    nParameters\n",
        "end\n",
        "\n",
        "(b::BatchNorm)(x) = batchnorm(x, b.moments, b.params)\n",
        "\n",
        "BatchNorm(C) = BatchNorm(bnmoments(), arrayType(bnparams(C)), 0)\n",
        "\n",
        "################################################################################\n",
        "\n",
        "struct Dense\n",
        "    w\n",
        "    b\n",
        "    f\n",
        "    pDrop\n",
        "    window\n",
        "    nParameters\n",
        "end\n",
        "\n",
        "Dense(i,o;\n",
        "    f=\n",
        "        identity,\n",
        "    window=\n",
        "        1,\n",
        "    xType=\n",
        "        Array{Float32},\n",
        "    scale=\n",
        "        0.01,\n",
        "    pDrop=\n",
        "        0\n",
        "    ) =\n",
        "        Dense(\n",
        "            Param(xType(rand(o,i)) .* eltype(xType)(scale), Adam()),\n",
        "            Param(xType(zeros(o)), Adam()),\n",
        "            f,\n",
        "            pDrop,\n",
        "            window,\n",
        "            (i+1)*o\n",
        "        )\n",
        "\n",
        "(d::Dense)(x) =\n",
        "    d.f.(\n",
        "        d.w *\n",
        "            mat(\n",
        "                dropout(x, d.pDrop),\n",
        "            ) .+ d.b\n",
        "        )\n",
        "\n",
        "\n",
        "################################################################################\n",
        "\n",
        "\n",
        "# Define a deconvolution layer:\n",
        "\n",
        "struct DeConv\n",
        "    w\n",
        "    b\n",
        "    padding\n",
        "    nParameters\n",
        "end\n",
        "\n",
        "\n",
        "DeConv(w1::Int, w2::Int, cx::Int, cy::Int;\n",
        "    padding=\n",
        "        0,\n",
        "    xType=\n",
        "        Array{Float32},\n",
        "    scale=\n",
        "        0.01\n",
        "    ) = DeConv(\n",
        "            Param(xType(rand(w1,w2,cx,cy)) .* eltype(xType)(scale), Adam()),\n",
        "            Param(xType(zeros(1,1,cy,1)), Adam()),\n",
        "            padding,\n",
        "            (w1*w2*cx)*cy\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "(dC::DeConv)(x) =\n",
        "    deconv4(\n",
        "        dC.w,\n",
        "        x,\n",
        "        padding=dC.padding\n",
        "    ) .+ b\n",
        "################################################################################\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvezH-bdvodN"
      },
      "source": [
        "# Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWW-0NQrvu91"
      },
      "source": [
        "\n",
        "# Define a body (up to bottleneck)\n",
        "mutable struct Body\n",
        "    layers\n",
        "    Body(layers...) = new(layers)\n",
        "end\n",
        "\n",
        "\n",
        "function addLayer!(b::Body, l)\n",
        "    b.layers = (\n",
        "        b.layers...,\n",
        "        l\n",
        "    )\n",
        "end\n",
        "\n",
        "\n",
        "(b::Body)(x) = (for l in b.layers;x = l(x);end;x)\n",
        "\n",
        "\n",
        "##################################\n",
        "\n",
        "# Define Head structure\n",
        "\n",
        "mutable struct Head\n",
        "    layers\n",
        "    lossF\n",
        "    Head(layers...; lossF=identity) = new(layers, lossF)\n",
        "end\n",
        "\n",
        "(h::Head)(x) = (for l in h.layers;x = l(x);end;x)\n",
        "\n",
        "\n",
        "\n",
        "###########################\n",
        "\n",
        "\n",
        "mutable struct Chain\n",
        "    body\n",
        "    heads\n",
        "    n\n",
        "    bottleneck\n",
        "    Chain(body, heads...; n=0, bottleneck=nothing) = new(body, heads..., n, bottleneck)\n",
        "end\n",
        "\n",
        "Chain(b::Body) = Chain(b, []; n=0)\n",
        "(c::Chain)(h::Head...) = addHead!(c, h...)\n",
        "\n",
        "function addHead!(c::Chain, h...)\n",
        "    c.heads = vcat(c.heads..., h...)\n",
        "    c.n = length(c.heads)\n",
        "end\n",
        "\n",
        "##########################################\n",
        "\n",
        "\n",
        "function meanLoss(c::Chain, d::Data)\n",
        "    J = [Float32(0) for n in 1:c.n]\n",
        "    for (j, (x, y)) in enumerate(d)\n",
        "        for (hIdx, (h, yi)) in enumerate(zip(c.heads, y))\n",
        "            J[hIdx] += h.lossF(h(c.body(x)), yi)\n",
        "        end\n",
        "    end\n",
        "    J ./ length(d)\n",
        "end\n",
        "\n",
        "\n",
        "every(n,itr) = (x for (i,x) in enumerate(itr) if i%n == 0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxe3J-5YvxbC"
      },
      "source": [
        "\n",
        "function train!(c::Chain, dTrn::Data, dTst::Data; iters=500, period=10)\n",
        "    results = []\n",
        "    for i=1:period:iters\n",
        "        push!(\n",
        "            results, (\n",
        "                c(dTrn),\n",
        "                c(dTst),\n",
        "                1-accuracy(c; data=dTrn),\n",
        "                1-accuracy(c; data=dTst)\n",
        "            )\n",
        "        )\n",
        "        for (x, y) in every(period, dTrn)\n",
        "            J = @diff c(x, y)\n",
        "            for p in params(J)\n",
        "                ∇p = grad(J, p)\n",
        "                update!(p, ∇p)\n",
        "            end\n",
        "        end\n",
        "    end\n",
        "    push!(\n",
        "        results, (\n",
        "            c(dTrn),\n",
        "            c(dTst),\n",
        "            1-accuracy(c; data=dTrn),\n",
        "            1-accuracy(c; data=dTst)\n",
        "        )\n",
        "    )\n",
        "    results = reshape(collect(Float32,flatten(results)),(4,:))\n",
        "    return 0:period:iters, results\n",
        "end\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsg77w_7wAZn"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Wjmk3ruwCNH"
      },
      "source": [
        "\n",
        "dTrn = minibatch(x, y; batchsize=Int32(100));\n",
        "\n",
        "dTst = minibatch(x, y; batchsize=Int32(100));\n",
        "\n",
        "\n",
        "\n",
        "seqLen = size(x, 1)\n",
        "\n",
        "tasks = [\n",
        "  \"22RV1.AR-C19\", \"22RV1.AR-V7\", \"LNCaP.dht.AR\", \"LNCaP.veh.AR\", \"22RV1.HOXB13\", \n",
        "  \"LN95.AR-C19\", \"LN95.AR-V7\", \"LN95.HOXB13\", \"malignant.1.AR\", \"malignant.2.AR\",\n",
        "  \"malignant.3.AR\", \"malignant.4.AR\", \"non-malignant.1.AR\", \"non-malignant.2.AR\"\n",
        "]\n",
        "\n",
        "\n",
        "bpnetBody = Body(\n",
        "    Conv(25,4,1,64, padding=(12, 0)) # Int(max((cx - 1) * s1 + w1 - cx, 0)/2)\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "nLayer = 2\n",
        "\n",
        "for i=1:nLayer\n",
        "    rate = 2^i\n",
        "    addLayer!(bpnetBody,\n",
        "        Conv(3,1,64,64, padding=(rate, 0), dilation=(rate, 0))\n",
        "    )\n",
        "end\n",
        "\n",
        "\n",
        "bpnet = Chain(bpnetBody)\n",
        "\n",
        "\n",
        "for task in tasks\n",
        "    profileHead = Head(\n",
        "        DeConv(25,1,2,64, padding=(12,0));\n",
        "        lossF=\n",
        "            multinomial_nll\n",
        "    )\n",
        "    println(\"profileHead\")\n",
        "    countHead = Head(\n",
        "        Dense(64,2, window=(seqLen,1));\n",
        "        lossF=\n",
        "            mse\n",
        "    )\n",
        "    println(\"countHead\")\n",
        "    bpnet(profileHead, countHead)\n",
        "end\n",
        "\n",
        "training = train!(bpnet, dTrn, dTst)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ4QU2Vkw8GV"
      },
      "source": [
        "\n",
        "[l.nParameters for l in collect(bpnet.body.layers)]\n",
        "[l.nParameters for h in collect(bpnet.heads) for l in h.layers]\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}