{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Julia on Colab.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Julia",
      "language": "julia",
      "name": "julia"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.5.2"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMSuTc3pDlHv",
        "outputId": "06b422fc-fd81-433f-e47b-2f4596ea95ec"
      },
      "source": [
        "%%shell\n",
        "set -e\n",
        "\n",
        "#---------------------------------------------------#\n",
        "JULIA_VERSION=\"1.5.2\" # any version ≥ 0.7.0\n",
        "JULIA_PACKAGES=\"IJulia BenchmarkTools PyCall PyPlot Knet HDF5 AutoGrad\"\n",
        "JULIA_PACKAGES_IF_GPU=\"CUDA\"\n",
        "JULIA_NUM_THREADS=4\n",
        "#---------------------------------------------------#\n",
        "\n",
        "if [ -n \"$COLAB_GPU\" ] && [ -z `which julia` ]; then\n",
        "  # Install Julia\n",
        "  JULIA_VER=`cut -d '.' -f -2 <<< \"$JULIA_VERSION\"`\n",
        "  echo \"Installing Julia $JULIA_VERSION on the current Colab Runtime...\"\n",
        "  BASE_URL=\"https://julialang-s3.julialang.org/bin/linux/x64\"\n",
        "  URL=\"$BASE_URL/$JULIA_VER/julia-$JULIA_VERSION-linux-x86_64.tar.gz\"\n",
        "  wget -nv $URL -O /tmp/julia.tar.gz # -nv means \"not verbose\"\n",
        "  tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1\n",
        "  rm /tmp/julia.tar.gz\n",
        "\n",
        "  # Install Packages\n",
        "  if [ \"$COLAB_GPU\" = \"1\" ]; then\n",
        "      JULIA_PACKAGES=\"$JULIA_PACKAGES $JULIA_PACKAGES_IF_GPU\"\n",
        "  fi\n",
        "  for PKG in `echo $JULIA_PACKAGES`; do\n",
        "    echo \"Installing Julia package $PKG...\"\n",
        "    julia -e 'using Pkg; pkg\"add '$PKG'; precompile;\"'\n",
        "  done\n",
        "\n",
        "  # Install kernel and rename it to \"julia\"\n",
        "  echo \"Installing IJulia kernel...\"\n",
        "  julia -e 'using IJulia; IJulia.installkernel(\"julia\", env=Dict(\n",
        "      \"JULIA_NUM_THREADS\"=>\"'\"$JULIA_NUM_THREADS\"'\"))'\n",
        "  KERNEL_DIR=`julia -e \"using IJulia; print(IJulia.kerneldir())\"`\n",
        "  KERNEL_NAME=`ls -d \"$KERNEL_DIR\"/julia*`\n",
        "  mv -f $KERNEL_NAME \"$KERNEL_DIR\"/julia\n",
        "\n",
        "  echo ''\n",
        "  echo \"Successfully installed `julia -v`!\"\n",
        "  echo \"Please reload this page (press Ctrl+R, ⌘+R, or the F5 key) then\"\n",
        "  echo \"jump to the 'Checking the Installation' section.\"\n",
        "fi\n",
        "\n",
        "\n",
        "echo -e \"function KnetArray(x::CuArray{T,N}) where {T,N}\\n\\tp = Base.bitcast(Cptr, pointer(x))\\n\\tk = KnetPtr(p, sizeof(x), Int(CUDA.device().handle), x)\\n\\tKnetArray{T,N}(k, size(x))\\nend\" >> /root/.julia/packages/Knet/OYNCT/src/knetarrays/karray.jl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing Julia 1.5.2 on the current Colab Runtime...\n",
            "2020-11-27 20:42:53 URL:https://storage.googleapis.com/julialang2/bin/linux/x64/1.5/julia-1.5.2-linux-x86_64.tar.gz [105324048/105324048] -> \"/tmp/julia.tar.gz\" [1]\n",
            "Installing Julia package IJulia...\n",
            "\u001b[32m\u001b[1m Installing\u001b[22m\u001b[39m known registries into `~/.julia`\n",
            "######################################################################## 100.0%\n",
            "\u001b[32m\u001b[1m      Added\u001b[22m\u001b[39m registry `General` to `~/.julia/registries/General`\n",
            "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m ZeroMQ_jll ────── v4.3.2+5\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m IJulia ────────── v1.23.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m MbedTLS ───────── v1.0.3\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Artifacts ─────── v1.3.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m MbedTLS_jll ───── v2.16.8+1\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m VersionParsing ── v1.2.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Conda ─────────── v1.5.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Parsers ───────── v1.0.12\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m JSON ──────────── v0.21.1\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m JLLWrappers ───── v1.1.3\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m ZMQ ───────────── v1.2.1\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m SoftGlobalScope ─ v1.1.0\n",
            "\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: ZeroMQ\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: MbedTLS\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Project.toml`\n",
            " \u001b[90m [7073ff75] \u001b[39m\u001b[92m+ IJulia v1.23.0\u001b[39m\n",
            "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Manifest.toml`\n",
            " \u001b[90m [56f22d72] \u001b[39m\u001b[92m+ Artifacts v1.3.0\u001b[39m\n",
            " \u001b[90m [8f4d0f93] \u001b[39m\u001b[92m+ Conda v1.5.0\u001b[39m\n",
            " \u001b[90m [7073ff75] \u001b[39m\u001b[92m+ IJulia v1.23.0\u001b[39m\n",
            " \u001b[90m [692b3bcd] \u001b[39m\u001b[92m+ JLLWrappers v1.1.3\u001b[39m\n",
            " \u001b[90m [682c06a0] \u001b[39m\u001b[92m+ JSON v0.21.1\u001b[39m\n",
            " \u001b[90m [739be429] \u001b[39m\u001b[92m+ MbedTLS v1.0.3\u001b[39m\n",
            " \u001b[90m [c8ffd9c3] \u001b[39m\u001b[92m+ MbedTLS_jll v2.16.8+1\u001b[39m\n",
            " \u001b[90m [69de0a69] \u001b[39m\u001b[92m+ Parsers v1.0.12\u001b[39m\n",
            " \u001b[90m [b85f4697] \u001b[39m\u001b[92m+ SoftGlobalScope v1.1.0\u001b[39m\n",
            " \u001b[90m [81def892] \u001b[39m\u001b[92m+ VersionParsing v1.2.0\u001b[39m\n",
            " \u001b[90m [c2297ded] \u001b[39m\u001b[92m+ ZMQ v1.2.1\u001b[39m\n",
            " \u001b[90m [8f1865be] \u001b[39m\u001b[92m+ ZeroMQ_jll v4.3.2+5\u001b[39m\n",
            " \u001b[90m [2a0f44e3] \u001b[39m\u001b[92m+ Base64\u001b[39m\n",
            " \u001b[90m [ade2ca70] \u001b[39m\u001b[92m+ Dates\u001b[39m\n",
            " \u001b[90m [8ba89e20] \u001b[39m\u001b[92m+ Distributed\u001b[39m\n",
            " \u001b[90m [7b1f6079] \u001b[39m\u001b[92m+ FileWatching\u001b[39m\n",
            " \u001b[90m [b77e0a4c] \u001b[39m\u001b[92m+ InteractiveUtils\u001b[39m\n",
            " \u001b[90m [76f85450] \u001b[39m\u001b[92m+ LibGit2\u001b[39m\n",
            " \u001b[90m [8f399da3] \u001b[39m\u001b[92m+ Libdl\u001b[39m\n",
            " \u001b[90m [56ddb016] \u001b[39m\u001b[92m+ Logging\u001b[39m\n",
            " \u001b[90m [d6f4376e] \u001b[39m\u001b[92m+ Markdown\u001b[39m\n",
            " \u001b[90m [a63ad114] \u001b[39m\u001b[92m+ Mmap\u001b[39m\n",
            " \u001b[90m [44cfe95a] \u001b[39m\u001b[92m+ Pkg\u001b[39m\n",
            " \u001b[90m [de0858da] \u001b[39m\u001b[92m+ Printf\u001b[39m\n",
            " \u001b[90m [3fa0cd96] \u001b[39m\u001b[92m+ REPL\u001b[39m\n",
            " \u001b[90m [9a3f8284] \u001b[39m\u001b[92m+ Random\u001b[39m\n",
            " \u001b[90m [ea8e919c] \u001b[39m\u001b[92m+ SHA\u001b[39m\n",
            " \u001b[90m [9e88b42a] \u001b[39m\u001b[92m+ Serialization\u001b[39m\n",
            " \u001b[90m [6462fe0b] \u001b[39m\u001b[92m+ Sockets\u001b[39m\n",
            " \u001b[90m [8dfed614] \u001b[39m\u001b[92m+ Test\u001b[39m\n",
            " \u001b[90m [cf7118a7] \u001b[39m\u001b[92m+ UUIDs\u001b[39m\n",
            " \u001b[90m [4ec0a83e] \u001b[39m\u001b[92m+ Unicode\u001b[39m\n",
            "\u001b[32m\u001b[1m   Building\u001b[22m\u001b[39m Conda ─→ `~/.julia/packages/Conda/x5ml4/deps/build.log`\n",
            "\u001b[32m\u001b[1m   Building\u001b[22m\u001b[39m IJulia → `~/.julia/packages/IJulia/ljYVo/deps/build.log`\n",
            "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "Installing Julia package BenchmarkTools...\n",
            "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
            "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m BenchmarkTools ─ v0.5.0\n",
            "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Project.toml`\n",
            " \u001b[90m [6e4b80f9] \u001b[39m\u001b[92m+ BenchmarkTools v0.5.0\u001b[39m\n",
            "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Manifest.toml`\n",
            " \u001b[90m [6e4b80f9] \u001b[39m\u001b[92m+ BenchmarkTools v0.5.0\u001b[39m\n",
            " \u001b[90m [37e2e46d] \u001b[39m\u001b[92m+ LinearAlgebra\u001b[39m\n",
            " \u001b[90m [2f01184e] \u001b[39m\u001b[92m+ SparseArrays\u001b[39m\n",
            " \u001b[90m [10745b16] \u001b[39m\u001b[92m+ Statistics\u001b[39m\n",
            "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "Installing Julia package PyCall...\n",
            "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
            "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m MacroTools ─ v0.5.6\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m PyCall ───── v1.92.1\n",
            "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Project.toml`\n",
            " \u001b[90m [438e738f] \u001b[39m\u001b[92m+ PyCall v1.92.1\u001b[39m\n",
            "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Manifest.toml`\n",
            " \u001b[90m [1914dd2f] \u001b[39m\u001b[92m+ MacroTools v0.5.6\u001b[39m\n",
            " \u001b[90m [438e738f] \u001b[39m\u001b[92m+ PyCall v1.92.1\u001b[39m\n",
            "\u001b[32m\u001b[1m   Building\u001b[22m\u001b[39m PyCall → `~/.julia/packages/PyCall/BcTLp/deps/build.log`\n",
            "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "Installing Julia package PyPlot...\n",
            "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
            "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Reexport ────────── v0.2.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m PyPlot ──────────── v2.9.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m LaTeXStrings ────── v1.2.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m ColorTypes ──────── v0.10.9\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m FixedPointNumbers ─ v0.8.4\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Colors ──────────── v0.12.4\n",
            "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Project.toml`\n",
            " \u001b[90m [d330b81b] \u001b[39m\u001b[92m+ PyPlot v2.9.0\u001b[39m\n",
            "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Manifest.toml`\n",
            " \u001b[90m [3da002f7] \u001b[39m\u001b[92m+ ColorTypes v0.10.9\u001b[39m\n",
            " \u001b[90m [5ae59095] \u001b[39m\u001b[92m+ Colors v0.12.4\u001b[39m\n",
            " \u001b[90m [53c48c17] \u001b[39m\u001b[92m+ FixedPointNumbers v0.8.4\u001b[39m\n",
            " \u001b[90m [b964fa9f] \u001b[39m\u001b[92m+ LaTeXStrings v1.2.0\u001b[39m\n",
            " \u001b[90m [d330b81b] \u001b[39m\u001b[92m+ PyPlot v2.9.0\u001b[39m\n",
            " \u001b[90m [189a3867] \u001b[39m\u001b[92m+ Reexport v0.2.0\u001b[39m\n",
            "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "Installing Julia package Knet...\n",
            "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
            "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Adapt ──────────────────────── v2.3.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m CEnum ──────────────────────── v0.4.1\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m AbstractFFTs ───────────────── v0.5.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Requires ───────────────────── v1.1.1\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Compat ─────────────────────── v3.23.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Zlib_jll ───────────────────── v1.2.11+18\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m BFloat16s ──────────────────── v0.1.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m DataStructures ─────────────── v0.18.8\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m AutoGrad ───────────────────── v1.2.3\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m GPUCompiler ────────────────── v0.8.3\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Knet ───────────────────────── v1.4.3\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m OrderedCollections ─────────── v1.3.2\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m ExprTools ──────────────────── v0.1.3\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Scratch ────────────────────── v1.0.3\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m CodecZlib ──────────────────── v0.7.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m CompilerSupportLibraries_jll ─ v0.3.4+0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m JLD2 ───────────────────────── v0.2.4\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m FileIO ─────────────────────── v1.4.4\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m LLVM ───────────────────────── v3.4.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m GPUArrays ──────────────────── v6.1.2\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m TranscodingStreams ─────────── v0.9.5\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m SpecialFunctions ───────────── v0.10.3\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m NNlib ──────────────────────── v0.7.7\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m TimerOutputs ───────────────── v0.5.7\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m CUDA ───────────────────────── v2.3.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m OpenSpecFun_jll ────────────── v0.5.3+4\n",
            "\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: libknet8\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: Zlib\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: CompilerSupportLibraries\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: OpenSpecFun\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Project.toml`\n",
            " \u001b[90m [1902f260] \u001b[39m\u001b[92m+ Knet v1.4.3\u001b[39m\n",
            "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Manifest.toml`\n",
            " \u001b[90m [621f4979] \u001b[39m\u001b[92m+ AbstractFFTs v0.5.0\u001b[39m\n",
            " \u001b[90m [79e6a3ab] \u001b[39m\u001b[92m+ Adapt v2.3.0\u001b[39m\n",
            " \u001b[90m [6710c13c] \u001b[39m\u001b[92m+ AutoGrad v1.2.3\u001b[39m\n",
            " \u001b[90m [ab4f0b2a] \u001b[39m\u001b[92m+ BFloat16s v0.1.0\u001b[39m\n",
            " \u001b[90m [fa961155] \u001b[39m\u001b[92m+ CEnum v0.4.1\u001b[39m\n",
            " \u001b[90m [052768ef] \u001b[39m\u001b[92m+ CUDA v2.3.0\u001b[39m\n",
            " \u001b[90m [944b1d66] \u001b[39m\u001b[92m+ CodecZlib v0.7.0\u001b[39m\n",
            " \u001b[90m [34da2185] \u001b[39m\u001b[92m+ Compat v3.23.0\u001b[39m\n",
            " \u001b[90m [e66e0078] \u001b[39m\u001b[92m+ CompilerSupportLibraries_jll v0.3.4+0\u001b[39m\n",
            " \u001b[90m [864edb3b] \u001b[39m\u001b[92m+ DataStructures v0.18.8\u001b[39m\n",
            " \u001b[90m [e2ba6199] \u001b[39m\u001b[92m+ ExprTools v0.1.3\u001b[39m\n",
            " \u001b[90m [5789e2e9] \u001b[39m\u001b[92m+ FileIO v1.4.4\u001b[39m\n",
            " \u001b[90m [0c68f7d7] \u001b[39m\u001b[92m+ GPUArrays v6.1.2\u001b[39m\n",
            " \u001b[90m [61eb1bfa] \u001b[39m\u001b[92m+ GPUCompiler v0.8.3\u001b[39m\n",
            " \u001b[90m [033835bb] \u001b[39m\u001b[92m+ JLD2 v0.2.4\u001b[39m\n",
            " \u001b[90m [1902f260] \u001b[39m\u001b[92m+ Knet v1.4.3\u001b[39m\n",
            " \u001b[90m [929cbde3] \u001b[39m\u001b[92m+ LLVM v3.4.0\u001b[39m\n",
            " \u001b[90m [872c559c] \u001b[39m\u001b[92m+ NNlib v0.7.7\u001b[39m\n",
            " \u001b[90m [efe28fd5] \u001b[39m\u001b[92m+ OpenSpecFun_jll v0.5.3+4\u001b[39m\n",
            " \u001b[90m [bac558e1] \u001b[39m\u001b[92m+ OrderedCollections v1.3.2\u001b[39m\n",
            " \u001b[90m [ae029012] \u001b[39m\u001b[92m+ Requires v1.1.1\u001b[39m\n",
            " \u001b[90m [6c6a2e73] \u001b[39m\u001b[92m+ Scratch v1.0.3\u001b[39m\n",
            " \u001b[90m [276daf66] \u001b[39m\u001b[92m+ SpecialFunctions v0.10.3\u001b[39m\n",
            " \u001b[90m [a759f4b9] \u001b[39m\u001b[92m+ TimerOutputs v0.5.7\u001b[39m\n",
            " \u001b[90m [3bb67fe8] \u001b[39m\u001b[92m+ TranscodingStreams v0.9.5\u001b[39m\n",
            " \u001b[90m [83775a58] \u001b[39m\u001b[92m+ Zlib_jll v1.2.11+18\u001b[39m\n",
            " \u001b[90m [8bb1440f] \u001b[39m\u001b[92m+ DelimitedFiles\u001b[39m\n",
            " \u001b[90m [1a1011a3] \u001b[39m\u001b[92m+ SharedArrays\u001b[39m\n",
            "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "Installing Julia package HDF5...\n",
            "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
            "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Blosc_jll ─── v1.14.3+1\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m LibCURL_jll ─ v7.70.0+2\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m OpenSSL_jll ─ v1.1.1+6\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Zstd_jll ──── v1.4.5+2\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m LibSSH2_jll ─ v1.9.0+3\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m nghttp2_jll ─ v1.40.0+2\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Blosc ─────── v0.7.0\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m HDF5 ──────── v0.14.1\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Lz4_jll ───── v1.9.2+2\n",
            "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m HDF5_jll ──── v1.12.0+1\n",
            "\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: Blosc\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: LibCURL\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: OpenSSL\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: LibSSH2\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: Zstd\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: nghttp2\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: Lz4\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: HDF5\n",
            "######################################################################## 100.0%\n",
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Project.toml`\n",
            " \u001b[90m [f67ccb44] \u001b[39m\u001b[92m+ HDF5 v0.14.1\u001b[39m\n",
            "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Manifest.toml`\n",
            " \u001b[90m [a74b3585] \u001b[39m\u001b[92m+ Blosc v0.7.0\u001b[39m\n",
            " \u001b[90m [0b7ba130] \u001b[39m\u001b[92m+ Blosc_jll v1.14.3+1\u001b[39m\n",
            " \u001b[90m [f67ccb44] \u001b[39m\u001b[92m+ HDF5 v0.14.1\u001b[39m\n",
            " \u001b[90m [0234f1f7] \u001b[39m\u001b[92m+ HDF5_jll v1.12.0+1\u001b[39m\n",
            " \u001b[90m [deac9b47] \u001b[39m\u001b[92m+ LibCURL_jll v7.70.0+2\u001b[39m\n",
            " \u001b[90m [29816b5a] \u001b[39m\u001b[92m+ LibSSH2_jll v1.9.0+3\u001b[39m\n",
            " \u001b[90m [5ced341a] \u001b[39m\u001b[92m+ Lz4_jll v1.9.2+2\u001b[39m\n",
            " \u001b[90m [458c3c95] \u001b[39m\u001b[92m+ OpenSSL_jll v1.1.1+6\u001b[39m\n",
            " \u001b[90m [3161d3a3] \u001b[39m\u001b[92m+ Zstd_jll v1.4.5+2\u001b[39m\n",
            " \u001b[90m [8e850ede] \u001b[39m\u001b[92m+ nghttp2_jll v1.40.0+2\u001b[39m\n",
            "\u001b[32m\u001b[1m   Building\u001b[22m\u001b[39m HDF5 → `~/.julia/packages/HDF5/LW5kO/deps/build.log`\n",
            "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "Installing Julia package AutoGrad...\n",
            "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
            "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Project.toml`\n",
            " \u001b[90m [6710c13c] \u001b[39m\u001b[92m+ AutoGrad v1.2.3\u001b[39m\n",
            "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.5/Manifest.toml`\n",
            "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "Installing Julia package CUDA...\n",
            "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
            "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Project.toml`\n",
            " \u001b[90m [052768ef] \u001b[39m\u001b[92m+ CUDA v2.3.0\u001b[39m\n",
            "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.5/Manifest.toml`\n",
            "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "Installing IJulia kernel...\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mInstalling julia kernelspec in /root/.local/share/jupyter/kernels/julia-1.5\n",
            "\n",
            "Successfully installed julia version 1.5.2!\n",
            "Please reload this page (press Ctrl+R, ⌘+R, or the F5 key) then\n",
            "jump to the 'Checking the Installation' section.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Rj1z5bRVKXk"
      },
      "source": [
        "# How to run?\n",
        "\n",
        "First know that this is a one-script notebook to run the entire project. \n",
        "\n",
        "\n",
        "1.   Run upper cell. (It install julia 1.5.2)\n",
        "2.   Restart the notebook. (This allows you to use julia language)\n",
        "3.   \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDjxPoocUt7y",
        "outputId": "9de99963-c327-472d-9bb9-bf6a3bd66c73"
      },
      "source": [
        "versioninfo()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Julia Version 1.5.2\n",
            "Commit 539f3ce943 (2020-09-23 23:17 UTC)\n",
            "Platform Info:\n",
            "  OS: Linux (x86_64-pc-linux-gnu)\n",
            "  CPU: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "  WORD_SIZE: 64\n",
            "  LIBM: libopenlibm\n",
            "  LLVM: libLLVM-9.0.1 (ORCJIT, broadwell)\n",
            "Environment:\n",
            "  JULIA_NUM_THREADS = 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bftwbelf5TzJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9515f3f-a996-4dbd-d54c-d2af1d105eee"
      },
      "source": [
        "using Knet\n",
        "using AutoGrad\n",
        "using HDF5\n",
        "using PyCall\n",
        "using CUDA; aType=(CUDA.functional() ? KnetArray{Float32} : Array{Float32})"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "┌ Info: Precompiling Knet [1902f260-5fb4-5aff-8c31-6271790ab950]\n",
            "└ @ Base loading.jl:1278\n",
            "WARNING: Method definition (::Type{Knet.KnetArrays.KnetArray{T, N} where N where T})(CUDA.CuArray{T, N}) where {T, N} in module KnetArrays at /root/.julia/packages/Knet/OYNCT/src/knetarrays/karray.jl:156 overwritten at /root/.julia/packages/Knet/OYNCT/src/knetarrays/karray.jl:170.\n",
            "  ** incremental compilation may be fatally broken for this module **\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: CUDA101\n",
            "\u001b[?25l"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "######################################################################### 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: CUDNN_CUDA101\n",
            "\u001b[?25l"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "######################################################################### 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: CUTENSOR_CUDA101\n",
            "\u001b[?25l"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "######################################################################### 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1A\u001b[2K\u001b[?25h"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KnetArray{Float32,N} where N"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm0GLhAHFJEA",
        "outputId": "516e44d9-20d7-46a5-9164-a0800f4f510e"
      },
      "source": [
        "CUDA.functional()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "true"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkaaAoQ6vYnH"
      },
      "source": [
        "# DATA\n",
        "\n",
        "Note that you should upload the DATA.hdf5.gz file to system each time you run, because it is recycled each time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B2-y-C06Oit",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "901c35b8-0d2a-4351-b4dd-1a376009b6ea"
      },
      "source": [
        "run(`gunzip DATA.hdf5.gz`)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Process(`\u001b[4mgunzip\u001b[24m \u001b[4mDATA.hdf5.gz\u001b[24m`, ProcessExited(0))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT_bcPrY6s33"
      },
      "source": [
        "fid = h5open(\"DATA.hdf5\", \"r\")\n",
        "\n",
        "xTrn = read(fid[\"trn\"][\"x\"]);\n",
        "xTst = read(fid[\"tst\"][\"x\"]);\n",
        "\n",
        "yTrn = [read(fid[\"trn\"][\"y\"][string(i)]) for i in 1:28];\n",
        "yTst = [read(fid[\"tst\"][\"y\"][string(i)]) for i in 1:28];\n",
        "\n",
        "heads = read(fid[\"heads\"]);\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnyv8Xus72dV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "725486c8-c56b-4575-edbb-ff13eb76b9a0"
      },
      "source": [
        "summary.([xTrn, yTrn, xTst, yTst])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4-element Array{String,1}:\n",
              " \"1000×4×1×13687 Array{Float32,4}\"\n",
              " \"28-element Array{Array{Float32,4},1}\"\n",
              " \"1000×4×1×13688 Array{Float32,4}\"\n",
              " \"28-element Array{Array{Float32,4},1}\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w-SGh8mvaxg",
        "outputId": "30e0bac2-9d39-466d-8886-ead1cd825460"
      },
      "source": [
        "\n",
        "\n",
        "# aType = Array{Float32}\n",
        "function minibatch(\n",
        "    x, y; batchsize::Int32=100, shuffle::Bool=false, atype::Type=Array{Float32})\n",
        "    \"\"\"\n",
        "    This function converts x and y data. Then initiates and returns Data type object.\n",
        "    \"\"\"\n",
        "    etype = eltype(atype)\n",
        "    x = aType(x)\n",
        "    y = [atype(yi) for yi in y]\n",
        "    n = size(x)[end]\n",
        "    Data(x,y, batchsize, shuffle, n, 1:n)\n",
        "end\n",
        "\n",
        "\n",
        "mutable struct Data\n",
        "    x\n",
        "    y\n",
        "    batchsize::Int32\n",
        "    shuffle::Bool\n",
        "    n::Int32\n",
        "    indices::Vector{Int32}\n",
        "end\n",
        "\n",
        "import Base: length, iterate, eltype, HasEltype\n",
        "\n",
        "function length(d::Data)\n",
        "    # Your code here\n",
        "    Int(ceil(d.n / d.batchsize))\n",
        "end\n",
        "\n",
        "\n",
        "\n",
        "function iterate(d::Data, state=(0)) # here the start point of state is 0\n",
        "    if state == 0 && d.shuffle\n",
        "        d.indices = randperm(d.n)\n",
        "    end\n",
        "\n",
        "    if state >= d.n\n",
        "        return nothing\n",
        "    end\n",
        "    i = state + 1 # here the beginning of the current slice\n",
        "    j = min(i+d.batchsize, d.n) # here the end of the current slice\n",
        "\n",
        "\n",
        "    idx = d.indices[i:j]\n",
        "    xbatch = d.x[:,:,:,idx]\n",
        "    ybatch = [y[:,:,:,idx] for y in d.y]\n",
        "\n",
        "    return ((xbatch, ybatch), j) # here it returns the batch and the next state of the iteration\n",
        "end\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "iterate (generic function with 337 methods)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APkBK6Qn8Q33"
      },
      "source": [
        "dTrn = minibatch(xTrn, yTrn; batchsize=Int32(100), atype=aType);\n",
        "dTst = minibatch(xTst, yTst; batchsize=Int32(100), atype=aType);"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_iwHl04vcxg"
      },
      "source": [
        "# Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "629S-2a3vgAg",
        "outputId": "eb6326fe-cebd-460a-923d-16463ac2850f"
      },
      "source": [
        "function aproxLogFact(n)\n",
        "    \"\"\"\n",
        "    Approximation for log n!\n",
        "    \"\"\"\n",
        "    n * log(n) - n  + log(n * (1 + 4n * (1 + 2n)))/6 + log(π)/2\n",
        "end\n",
        "\n",
        "\n",
        "function multinomial_nll(ypred, ytrue)\n",
        "    ypred .*= 0.0001\n",
        "    ytrue .*= 0.0001\n",
        "    ypred .+= 0.0001\n",
        "    ytrue .+= 0.0001\n",
        "    pV = ypred ./ sum(ypred, dims=1)\n",
        "    logPV = log.(pV)\n",
        "    pS = sum(logPV .* ytrue, dims=1)\n",
        "    n = sum(ytrue, dims=1)\n",
        "    nS = (aproxLogFact.(n) .- sum(aproxLogFact.(ytrue), dims=1))\n",
        "    logP = pS .+ nS\n",
        "    loss = sum(logP) / prod(size(logP))\n",
        "    loss * 0.1\n",
        "end\n",
        "\n",
        "function mse(ypred, ytrue)\n",
        "    λ = Float32(0.5) * sum(ypred) / size(ypred, 1)\n",
        "    C = λ * abs2.(log.(1 .+ sum(ypred)) .- log.(1 .+ ytrue)) ./ size(ypred, 1)\n",
        "    sum(C) / prod(size(C))\n",
        "end\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mse (generic function with 1 method)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vljgfJ1kvj_-"
      },
      "source": [
        "# Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8E7ygsZvmBz"
      },
      "source": [
        "mutable struct Conv\n",
        "    w\n",
        "    b\n",
        "    f\n",
        "    pDrop\n",
        "    padding\n",
        "    dilation\n",
        "    nParameters\n",
        "end\n",
        "\n",
        "\n",
        "\n",
        "(c::Conv)(x) =\n",
        "    c.f.(\n",
        "        conv4(\n",
        "            c.w,\n",
        "            dropout(x, c.pDrop),\n",
        "            padding=c.padding,\n",
        "            dilation=c.dilation\n",
        "        ) .+ c.b\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "Conv(w1::Int, w2::Int, cx::Int, cy::Int;\n",
        "    f=\n",
        "        relu,\n",
        "    pDrop=\n",
        "        0,\n",
        "    padding=\n",
        "        0,\n",
        "    dilation=\n",
        "        1,\n",
        "    aType=\n",
        "        Array{Float32},\n",
        "    scale=\n",
        "        0.01\n",
        "    ) = Conv(\n",
        "            Param(aType(rand(w1,w2,cx,cy)) .* eltype(aType)(scale), Adam()),\n",
        "            Param(aType(zeros(1,1,cy,1)), Adam()),\n",
        "            f,\n",
        "            pDrop,\n",
        "            padding,\n",
        "            dilation,\n",
        "            (w1*w2*cx +1)*cy \n",
        "        )\n",
        "\n",
        "################################################################################\n",
        "struct Pool\n",
        "    wSize\n",
        "    nParameters\n",
        "end\n",
        "\n",
        "(p::Pool)(x) = pool(x; window=p.wSize)\n",
        "Pool(x) = Pool(x, 0)\n",
        "################################################################################\n",
        "mutable struct BatchNorm\n",
        "    moments\n",
        "    params\n",
        "    nParameters\n",
        "end\n",
        "\n",
        "(b::BatchNorm)(x) = batchnorm(x, b.moments, b.params)\n",
        "\n",
        "BatchNorm(C) = BatchNorm(bnmoments(), aType(bnparams(C)), 0)\n",
        "\n",
        "################################################################################\n",
        "\n",
        "struct Dense\n",
        "    w\n",
        "    b\n",
        "    f\n",
        "    pDrop\n",
        "    window\n",
        "    nParameters\n",
        "end\n",
        "\n",
        "Dense(i,o;\n",
        "    f=\n",
        "        identity,\n",
        "    window=\n",
        "        1,\n",
        "    aType=\n",
        "        Array{Float32},\n",
        "    scale=\n",
        "        0.01,\n",
        "    pDrop=\n",
        "        0\n",
        "    ) =\n",
        "        Dense(\n",
        "            Param(aType(rand(o,i)) .* eltype(aType)(scale), Adam()),\n",
        "            Param(aType(zeros(o)), Adam()),\n",
        "            f,\n",
        "            pDrop,\n",
        "            window,\n",
        "            (i+1)*o\n",
        "        )\n",
        "\n",
        "(d::Dense)(x) =\n",
        "    d.f.(\n",
        "        d.w *\n",
        "            mat(\n",
        "                dropout(x, d.pDrop),\n",
        "            ) .+ d.b\n",
        "        )\n",
        "\n",
        "\n",
        "################################################################################\n",
        "\n",
        "\n",
        "# Define a deconvolution layer:\n",
        "\n",
        "struct DeConv\n",
        "    w\n",
        "    b\n",
        "    padding\n",
        "    nParameters\n",
        "end\n",
        "\n",
        "\n",
        "DeConv(w1::Int, w2::Int, cx::Int, cy::Int;\n",
        "    padding=\n",
        "        0,\n",
        "    aType=\n",
        "        Array{Float32},\n",
        "    scale=\n",
        "        0.01\n",
        "    ) = DeConv(\n",
        "            Param(aType(rand(w1,w2,cx,cy)) .* eltype(aType)(scale), Adam()),\n",
        "            Param(aType(zeros(1,1,cx,1)), Adam()),\n",
        "            padding,\n",
        "            (w1*w2*cx)*cy + cx\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "(dC::DeConv)(x) =\n",
        "    deconv4(\n",
        "        dC.w,\n",
        "        x,\n",
        "        padding=dC.padding\n",
        "    ) .+ dC.b\n",
        "################################################################################\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvezH-bdvodN"
      },
      "source": [
        "# Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWW-0NQrvu91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c410ed66-3726-4305-8490-c0338378db15"
      },
      "source": [
        "\n",
        "# Define a body (up to bottleneck)\n",
        "mutable struct Body\n",
        "    layers\n",
        "    Body(layers...) = new(layers)\n",
        "end\n",
        "\n",
        "\n",
        "function addLayer!(b::Body, l)\n",
        "    b.layers = (\n",
        "        b.layers...,\n",
        "        l\n",
        "    )\n",
        "end\n",
        "\n",
        "\n",
        "(b::Body)(x) = (for l in b.layers;x = l(x);end;x)\n",
        "\n",
        "\n",
        "##################################\n",
        "\n",
        "# Define Head structure\n",
        "\n",
        "mutable struct Head\n",
        "    layers\n",
        "    lossF\n",
        "    Head(layers...; lossF=identity) = new(layers, lossF)\n",
        "end\n",
        "\n",
        "(h::Head)(x) = (for l in h.layers;x = l(x);end;x)\n",
        "\n",
        "\n",
        "\n",
        "###########################\n",
        "\n",
        "\n",
        "mutable struct Chain\n",
        "    body\n",
        "    heads\n",
        "    n\n",
        "    bottleneck\n",
        "    Chain(body, heads...; n=0, bottleneck=nothing) = new(body, heads..., n, bottleneck)\n",
        "end\n",
        "\n",
        "Chain(b::Body) = Chain(b, []; n=0)\n",
        "(c::Chain)(h::Head...) = addHead!(c, h...)\n",
        "\n",
        "function addHead!(c::Chain, h...)\n",
        "    c.heads = vcat(c.heads..., h...)\n",
        "    c.n = length(c.heads)\n",
        "end\n",
        "\n",
        "##########################################\n",
        "\n",
        "\n",
        "function meanLoss(c::Chain, d::Data)\n",
        "    J = [Float32(0) for n in 1:c.n]\n",
        "    for (j, (x, y)) in enumerate(d)\n",
        "        for (hIdx, (h, yi)) in enumerate(zip(c.heads, y))\n",
        "            J[hIdx] += h.lossF(h(c.body(x)), yi)\n",
        "        end\n",
        "    end\n",
        "    J ./ length(d)\n",
        "end\n",
        "\n",
        "\n",
        "every(n,itr) = (x for (i,x) in enumerate(itr) if i%n == 0)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "every (generic function with 1 method)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxe3J-5YvxbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec355bd9-31f1-4567-ff65-5fdd17df43dc"
      },
      "source": [
        "\n",
        "function train!(c::Chain, dTrn::Data, dTst::Data; iters=500, period=10)\n",
        "    results = []\n",
        "    for i=1:period:iters\n",
        "        push!(\n",
        "            results, (\n",
        "                meanLoss(bpnet, dTrn),\n",
        "                meanLoss(bpnet, dTst),\n",
        "                1-meanAccuracy(bpnet, dTrn),\n",
        "                1-meanAccuracy(bpnet, dTst)\n",
        "            )\n",
        "        )\n",
        "        println(\"Period: \", period)\n",
        "        println(\"Loss: \", meanLoss(bpnet, dTst))\n",
        "        println(\"Accuracy: \", meanAccuracy(bpnet, dTst))\n",
        "        for (x, y) in every(period, dTrn)\n",
        "            J = @diff c(x, y)\n",
        "            for p in params(J)\n",
        "                ∇p = grad(J, p)\n",
        "                update!(p, ∇p)\n",
        "            end\n",
        "        end\n",
        "    end\n",
        "    push!(\n",
        "        results, (\n",
        "            meanLoss(bpnet, dTrn),\n",
        "            meanLoss(bpnet, dTst),\n",
        "            1 .- meanAccuracy(bpnet, dTrn),\n",
        "            1 .- meanAccuracy(bpnet, dTst)\n",
        "        )\n",
        "    )\n",
        "    results = reshape(collect(Float32,flatten(results)),(4,:))\n",
        "    return 0:period:iters, results\n",
        "end\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "train! (generic function with 1 method)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGFnCdZHTNBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "559cfa24-d3c6-4995-e624-be51ab01970d"
      },
      "source": [
        "\n",
        "function meanLoss(c::Chain, d::Data)\n",
        "    J = [Float32(0) for n in 1:c.n]\n",
        "    for (j, (x, y)) in enumerate(d)\n",
        "        for (hIdx, (h, yi)) in enumerate(zip(c.heads, y))\n",
        "            J[hIdx] += h.lossF(h(c.body(x)), yi)\n",
        "        end\n",
        "    end\n",
        "    J ./ length(d)\n",
        "end\n",
        "\n",
        "\n",
        "function meanAccuracy(c::Chain, d::Data)\n",
        "    A = [Float32(0) for n in 1:c.n]\n",
        "    for (j, (x, y)) in enumerate(d)\n",
        "        for (hIdx, (h, yi)) in enumerate(zip(c.heads, y))\n",
        "            A[hIdx] += sum(h(c.body(x)) .== yi)\n",
        "        end\n",
        "    end\n",
        "    A ./ d.n\n",
        "end\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "meanAccuracy (generic function with 1 method)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsg77w_7wAZn"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Wjmk3ruwCNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d9ff149-109b-4fb5-aa5e-30bf4a320d0e"
      },
      "source": [
        "seqLen = size(xTrn, 1)\n",
        "\n",
        "tasks = [\n",
        "  \"22RV1.AR-C19\", \"22RV1.AR-V7\", \"LNCaP.dht.AR\", \"LNCaP.veh.AR\", \"22RV1.HOXB13\",\n",
        "  \"LN95.AR-C19\", \"LN95.AR-V7\", \"LN95.HOXB13\", \"malignant.1.AR\", \"malignant.2.AR\",\n",
        "  \"malignant.3.AR\", \"malignant.4.AR\", \"non-malignant.1.AR\", \"non-malignant.2.AR\"\n",
        "]\n",
        "\n",
        "bpnetBody = Body(\n",
        "    Conv(25,4,1,64; padding=(12, 0), aType=aType) # Int(max((cx - 1) * s1 + w1 - cx, 0)/2)\n",
        ")\n",
        "\n",
        "nLayer = 2\n",
        "\n",
        "for i=1:nLayer\n",
        "    rate = 2^i\n",
        "    addLayer!(bpnetBody,\n",
        "        Conv(3,1,64,64; padding=(rate, 0), dilation=(rate, 1), aType=aType)\n",
        "    )\n",
        "end\n",
        "\n",
        "\n",
        "bpnet = Chain(bpnetBody)\n",
        "\n",
        "\n",
        "for task in tasks\n",
        "    profileHead = Head(\n",
        "        DeConv(25,1,2,64, padding=(12,0), aType=aType);\n",
        "        lossF=\n",
        "            multinomial_nll\n",
        "    )\n",
        "    println(\"profileHead\")\n",
        "    countHead = Head(\n",
        "        Pool((seqLen, 1)),\n",
        "        Dense(64,2, window=(seqLen,1), aType=aType);\n",
        "        lossF=\n",
        "            mse\n",
        "    )\n",
        "    println(\"countHead\")\n",
        "    bpnet(profileHead, countHead)\n",
        "end\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "profileHead\n",
            "countHead\n",
            "profileHead\n",
            "countHead\n",
            "profileHead\n",
            "countHead\n",
            "profileHead\n",
            "countHead\n",
            "profileHead\n",
            "countHead\n",
            "profileHead\n",
            "countHead\n",
            "profileHead\n",
            "countHead\n",
            "profileHead\n",
            "countHead\n",
            "profileHead\n",
            "countHead\n",
            "profileHead\n",
            "countHead\n",
            "profileHead\n",
            "countHead\n",
            "profileHead\n",
            "countHead\n",
            "profileHead\n",
            "countHead\n",
            "profileHead\n",
            "countHead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zK29jFJTPXm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2ddcf53-fdbe-4f3e-cfd5-e4f7ab941073"
      },
      "source": [
        "function KnetArray(x::CuArray{T,N}) where {T,N}\n",
        "    p = Base.bitcast(Knet.Cptr, pointer(x))\n",
        "    k = Knet.KnetPtr(p, sizeof(x), Int(CUDA.device().handle), x)\n",
        "    KnetArray{T,N}(k, size(x))\n",
        "end\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KnetArray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-aQ0idlFPRQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4b97e8b-33f0-4101-b91a-82d9f82827f1"
      },
      "source": [
        "@time meanLoss(bpnet, dTrn)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 22.830560 seconds (2.96 M allocations: 122.973 MiB, 2.19% gc time)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28-element Array{Float32,1}:\n",
              " 9.50673\n",
              " 2.2678998\n",
              " 9.526855\n",
              " 1.5817437\n",
              " 9.344586\n",
              " 7.546295\n",
              " 9.464742\n",
              " 4.1384997\n",
              " 9.4556675\n",
              " 4.0408\n",
              " 9.512998\n",
              " 1.9688777\n",
              " 9.521675\n",
              " ⋮\n",
              " 9.526413\n",
              " 1.2967345\n",
              " 9.522954\n",
              " 1.6352444\n",
              " 9.510297\n",
              " 2.4569547\n",
              " 9.530515\n",
              " 1.3682952\n",
              " 9.526314\n",
              " 1.7141634\n",
              " 9.530331\n",
              " 1.3192456"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIf12FcWh5Dm",
        "outputId": "7f1ebaa9-1c3c-49ed-c85b-f8fa46cc66d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "@time meanAccuracy(bpnet, dTrn)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 21.997568 seconds (2.11 M allocations: 95.635 MiB, 1.98% gc time)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28-element Array{Float32,1}:\n",
              " 0.14480895\n",
              " 0.0\n",
              " 0.14480895\n",
              " 0.0\n",
              " 0.14480895\n",
              " 0.0\n",
              " 0.14480895\n",
              " 0.0\n",
              " 0.14480895\n",
              " 0.0\n",
              " 0.14480895\n",
              " 0.0\n",
              " 0.14480895\n",
              " ⋮\n",
              " 0.14480895\n",
              " 0.0\n",
              " 0.14480895\n",
              " 0.0\n",
              " 0.14480895\n",
              " 0.0\n",
              " 0.14480895\n",
              " 0.0\n",
              " 0.14480895\n",
              " 0.0\n",
              " 0.14480895\n",
              " 0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ4QU2Vkw8GV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff219335-fe43-4807-ae3d-7c83cd3ad167"
      },
      "source": [
        "\n",
        "[l.nParameters for l in collect(bpnet.body.layers)]\n",
        "[l.nParameters for h in collect(bpnet.heads) for l in h.layers]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28-element Array{Int64,1}:\n",
              " 3200\n",
              "  130\n",
              " 3200\n",
              "  130\n",
              " 3200\n",
              "  130\n",
              " 3200\n",
              "  130\n",
              " 3200\n",
              "  130\n",
              " 3200\n",
              "  130\n",
              " 3200\n",
              "    ⋮\n",
              " 3200\n",
              "  130\n",
              " 3200\n",
              "  130\n",
              " 3200\n",
              "  130\n",
              " 3200\n",
              "  130\n",
              " 3200\n",
              "  130\n",
              " 3200\n",
              "  130"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwDle9td81Eo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "9a120dfa-667e-4997-ca17-2effea82643c"
      },
      "source": [
        "@time training = train!(bpnet, dTrn, dTst)\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LoadError",
          "evalue": "ignored",
          "traceback": [
            "InterruptException:",
            "",
            "Stacktrace:",
            " [1] pointer(::KnetArray{Float32,2}) at /root/.julia/packages/Knet/OYNCT/src/knetarrays/karray.jl:137",
            " [2] unsafe_convert(::Type{Ptr{Float32}}, ::KnetArray{Float32,2}) at /root/.julia/packages/Knet/OYNCT/src/knetarrays/karray.jl:136",
            " [3] #sum#101 at /root/.julia/packages/Knet/OYNCT/src/knetarrays/reduction.jl:32 [inlined]",
            " [4] sum at /root/.julia/packages/Knet/OYNCT/src/knetarrays/reduction.jl:31 [inlined]",
            " [5] mse(::KnetArray{Float32,2}, ::KnetArray{Float32,4}) at ./In[29]:26",
            " [6] meanLoss(::Chain, ::Data) at ./In[44]:6",
            " [7] train!(::Chain, ::Data, ::Data; iters::Int64, period::Int64) at ./In[43]:5",
            " [8] train! at ./In[43]:3 [inlined]",
            " [9] top-level scope at ./timing.jl:174 [inlined]",
            " [10] top-level scope at ./In[45]:0",
            " [11] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
          ]
        }
      ]
    }
  ]
}